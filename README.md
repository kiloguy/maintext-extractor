A main text extractor for extracting the main content from a web page using Python Selenium ChromeDirver, BeautifulSoup 
and flask as an API server.

Python Dependency
------------------
- `selenium`
- `bs4`
- `flask`

Usage
---------
This extractor runs 4 Selenium driver in background using multiple thread and serve as an server using flask.
To run the server, simply run the following:
```
$ python server.py
```
or run in the background (bash environment):
```
$ python server.py &>> log.txt &
```
To use the extractor, use HTTP requesting tools like `curl` or [Postman](https://www.postman.com/) to send a GET request to the server:
```
GET http://localhost:5001/[encoded URL]
```
the URL appended after slash must be encoded by URL encoding.
The response is a JSON format. For example, the following request:
```
GET http://3.112.43.166:5001/https%3A%2F%2Fblog.gtwang.org%2Fprogramming%2Fpython-threading-multithreaded-programming-tutorial%2F
```
will response
```json
{
    "driver": 0,
    "duration": 15.371827125549316,
    "url": "https://blog.gtwang.org/programming/python-threading-multithreaded-programming-tutorial/",
    "maintext": "物聯網\n網站架設\n程式設計\n統計\n素食\n特價優惠\n宗教\nPython 多執行緒 threading 模組平行化程式設計教學\n4 則留言\n本篇介紹如何在 Python 中使用 threading 模組，撰寫多執行緒的平行計算程式，利用多顆 CPU 核心加速運算。\n現在電腦的 CPU 都有許多的核心，若想要讓程式可以運用多顆 CPU 核心，充分發揮硬體的運算能力，就必須考慮使用多執行緒（multithreading）或多行程（multiprocessing）等平行化的技術，以下介紹 Python 的多執行緒的程式設計方法與技巧，並提供詳細的範例程式碼。\n由於 CPython 的 GIL（Global Interpreter Lock）限制，可能會造成大部分的 Python 程式無法以多執行緒發揮多核心 CPU 的效能，若遇到這樣的狀況，可以考慮改用多行程的方式來設計程式。\nthreading 模組\n在 Python 中若要撰寫多執行緒（multithreading）的平行化程式，最基本的方式是使用 threading 這個模組來建立子執行緒。\nthreading 是 Python 標準函式庫裡面的模組，所以不用特別安裝即可使用，雖然功能不是很多，但是基本多執行緒程式設計常用的功能它都有，對於比較單純的平行化工作來說，還算滿實用了。\n建立子執行緒\n以下是使用 threading 模組建立子執行緒的範例：\nimport threading\nimport time\n\n# 子執行緒的工作函數\ndef job():\n  for i in range(5):\n    print(\"Child thread:\", i)\n    time.sleep(1)\n\n# 建立一個子執行緒\nt = threading.Thread(target = job)\n\n# 執行該子執行緒\nt.start()\n\n# 主執行緒繼續執行自己的工作\nfor i in range(3):\n  print(\"Main thread:\", i)\n  time.sleep(1)\n\n# 等待 t 這個子執行緒結束\nt.join()\n\nprint(\"Done.\")\n在這個例子中，我們先定義一個要讓子執行緒執行的 job 函數，接著使用 threading.Thread 建立一個新的子執行緒，其 target 參數就指定為要讓子執行緒執行的函數（也就是 job）。\n建立好新的執行緒之後，即可呼叫執行緒的 start 函數，讓它開始執行，在子執行緒執行的同時，我們還是可以在主程式中繼續處理其他的工作。\n如果有些工作是要等待子執行緒執行完成後才能處理的話，可以使用執行緒的 join 函數，等待該執行緒執行結束，也就是說放在 join 之後的程式碼就會等到子執行緒執行完成後，才會接著執行。\n執行後的輸出會類似這樣：\nChild thread: 0\nMain thread: 0\nMain thread: 1\nChild thread: 1\nMain thread: 2\nChild thread: 2\nChild thread: 3\nChild thread: 4\nDone.\n這裡的子執行緒會執行 5 秒，但是主程式中的迴圈只要 3 秒就結束了，所以主程式會在 join 的地方等待 2 秒鐘，等到子執行緒結束之後，才會輸出 Done. 這一行訊息。\n多個子執行緒與參數\n通常我們在撰寫平行化的程式時，都會使用多個子執行緒，並且傳入不同的參數，讓個子執行緒各自負責不同的工作，這時候就可以在建立子執行緒時，使用 args 參數指定要傳數的參數。以下是一個簡單的範例：\nimport threading\nimport time\n\n# 子執行緒的工作函數\ndef job(num):\n  print(\"Thread\", num)\n  time.sleep(1)\n\n# 建立 5 個子執行緒\nthreads = []\nfor i in range(5):\n  threads.append(threading.Thread(target = job, args = (i,)))\n  threads[i].start()\n\n# 主執行緒繼續執行自己的工作\n# ...\n\n# 等待所有子執行緒結束\nfor i in range(5):\n  threads[i].join()\n\nprint(\"Done.\")\n在這個例子中，我們讓子執行緒執行的 job 函數會接受一個 num 參數，依據這個參數來決定要處理什麼工作，然後在呼叫 threading.Thread 建立子執行緒時，將要傳入的參數放在 args 參數中，這樣就可以把資料傳進子執行緒的 job 函數中了。執行之後的結果如下：\nThread 0\nThread 1\nThread 2\nThread 3\nThread 4\nDone.\n物件導向\n我們也可以使用 Python 物件導向的方式來改寫 threading 的多執行緒程式，以下是一個簡單的範例：\nimport threading\nimport time\n\n# 子執行緒類別\nclass MyThread(threading.Thread):\n  def __init__(self, num):\n    threading.Thread.__init__(self)\n    self.num = num\n\n  def run(self):\n    print(\"Thread\", self.num)\n    time.sleep(1)\n\n# 建立 5 個子執行緒\nthreads = []\nfor i in range(5):\n  threads.append(MyThread(i))\n  threads[i].start()\n\n# 主執行緒繼續執行自己的工作\n# ...\n\n# 等待所有子執行緒結束\nfor i in range(5):\n  threads[i].join()\n\nprint(\"Done.\")\n這個範例大致上的觀念都跟前面差不多，比較需要注意的地方就是 threading.Thread 在開始執行時，會呼叫它自己的 run 方法函數，這個方法函數預設會呼叫前面我們以 target 參數所指定的函數，在這裡我們在繼承 threading.Thread 類別之後，就直接把 run 覆寫成要執行的函數即可。\n這個範例的執行結果跟上一個例子相同：\nThread 0\nThread 1\nThread 2\nThread 3\nThread 4\nDone.\n佇列（Queue）\n如果我們有許多的工作要分給多個 CPU 核心做運算，最簡單的方式就是使用佇列的方式，讓多個 CPU 可從佇列中取得尚未處理的工作來處理：\nimport time\nimport threading\nimport queue\n\n# Worker 類別，負責處理資料\nclass Worker(threading.Thread):\n  def __init__(self, queue, num):\n    threading.Thread.__init__(self)\n    self.queue = queue\n    self.num = num\n\n  def run(self):\n    while self.queue.qsize() > 0:\n      # 取得新的資料\n      msg = self.queue.get()\n\n      # 處理資料\n      print(\"Worker %d: %s\" % (self.num, msg))\n      time.sleep(1)\n\n# 建立佇列\nmy_queue = queue.Queue()\n\n# 將資料放入佇列\nfor i in range(10):\n  my_queue.put(\"Data %d\" % i)\n\n# 建立兩個 Worker\nmy_worker1 = Worker(my_queue, 1)\nmy_worker2 = Worker(my_queue, 2)\n\n# 讓 Worker 開始處理資料\nmy_worker1.start()\nmy_worker2.start()\n\n# 等待所有 Worker 結束\nmy_worker1.join()\nmy_worker2.join()\n\nprint(\"Done.\")\n這裡我們建立兩個 Worker，它們都會從佇列中取得尚未處理的資料，直到佇列清空為止。執行後的結果會像這樣：\nWorker 1: Data 0\nWorker 2: Data 1\nWorker 1: Data 2\nWorker 2: Data 3\nWorker 2: Data 4\nWorker 1: Data 5\nWorker 1: Data 6\nWorker 2: Data 7\nWorker 2: Data 8\nWorker 1: Data 9\nDone.\n鎖定（Lock）\n在平行化的多執行緒程式中，每個執行緒都是同時在執行的，若遇到不可以讓多個執行緒同時進行的工作時（例如將資料寫入同一個檔案），就必須使用鎖定（lock）的方式，一次只讓一個執行緒處理這種工作。\n在 Python 中，我們可以使用 threading 模組的 Lock 來處理多執行緒的鎖定問題，以下是一個簡單的使用範例：\nimport time\nimport threading\nimport queue\n\nclass Worker(threading.Thread):\n  def __init__(self, queue, num, lock):\n    threading.Thread.__init__(self)\n    self.queue = queue\n    self.num = num\n    self.lock = lock\n\n  def run(self):\n    while self.queue.qsize() > 0:\n      msg = self.queue.get()\n\n      # 取得 lock\n      self.lock.acquire()\n      print(\"Lock acquired by Worker %d\" % self.num)\n\n      # 不能讓多個執行緒同時進的工作\n      print(\"Worker %d: %s\" % (self.num, msg))\n      time.sleep(1)\n\n      # 釋放 lock\n      print(\"Lock released by Worker %d\" % self.num)\n      self.lock.release()\n\nmy_queue = queue.Queue()\nfor i in range(5):\n  my_queue.put(\"Data %d\" % i)\n\n# 建立 lock\nlock = threading.Lock()\n\nmy_worker1 = Worker(my_queue, 1, lock)\nmy_worker2 = Worker(my_queue, 2, lock)\n\nmy_worker1.start()\nmy_worker2.start()\n\nmy_worker1.join()\nmy_worker2.join()\n\nprint(\"Done.\")\n在這個範例中，我們讓兩個 Worker 都從佇列中取得待處理的工作，但是我們使用一個 Lock 限制一次只允許一個 Worker 來處理工作。\n當一個執行緒呼叫了 Lock 的 acquire 時，代表取得了這個 Lock 的使用權，接著它就可以往下執行裡面的工作，若此時又有另外一個執行緒想要呼叫 acquire 取得使用權的話，就必須等待上一個執行緒執行完，並呼叫 release 釋放這個 Lock 之後，才能夠取得這個 Lock 的使用權，接著執行裡面的工作。\n在這種狀況下雖然兩個 Worker 是同時執行的，但是由於 Lock 的互斥作用，因此可以確保被 Lock 的 acquire 與 release 包起來的這段程式碼不會被兩個執行緒同時執行。\n執行的結果如下：\nLock acquired by Worker 1\nWorker 1: Data 0\nLock released by Worker 1\nLock acquired by Worker 2\nWorker 2: Data 1\nLock released by Worker 2\nLock acquired by Worker 1\nWorker 1: Data 2\nLock released by Worker 1\nLock acquired by Worker 2\nWorker 2: Data 3\nLock released by Worker 2\nLock acquired by Worker 1\nWorker 1: Data 4\nLock released by Worker 1\nDone.\n旗標（Semaphore）\n有時候因為系統資源有限的因素（例如考量 CPU 或記憶體的限制），在處理某些特別耗資源的工作時，僅允許有限個執行緒同時進行，這個狀況跟上面介紹的鎖定（lock）有點類似，但是鎖定的方式是僅允許一個執行緒進行某項工作，而這裡我們是允許多個執行緒同時執行的，但要限制同時執行的執行緒數量上限。\n旗標（semaphore）的作用跟鎖定（lock）類似，但是它多了一個計數器的功能，當一個執行緒呼叫了 acquire 時，旗標內部的計數器就會遞減 1，而當執行緒呼叫了 release 時，計數器就會遞增 1，當計數器遞減到 0 的時候，後面來的執行緒就要等待其他執行緒release 後才能繼續。\n以下是一個簡單的範例：\nimport time\nimport threading\nimport queue\n\nclass Worker(threading.Thread):\n  def __init__(self, queue, num, semaphore):\n    threading.Thread.__init__(self)\n    self.queue = queue\n    self.num = num\n    self.semaphore = semaphore\n\n  def run(self):\n    while self.queue.qsize() > 0:\n      msg = self.queue.get()\n\n      # 取得旗標\n      semaphore.acquire()\n      print(\"Semaphore acquired by Worker %d\" % self.num)\n\n      # 僅允許有限個執行緒同時進的工作\n      print(\"Worker %d: %s\" % (self.num, msg))\n      time.sleep(1)\n\n      # 釋放旗標\n      print(\"Semaphore released by Worker %d\" % self.num)\n      self.semaphore.release()\n\nmy_queue = queue.Queue()\nfor i in range(5):\n  my_queue.put(\"Data %d\" % i)\n\n# 建立旗標\nsemaphore = threading.Semaphore(2)\n\nmy_worker1 = Worker(my_queue, 1, semaphore)\nmy_worker2 = Worker(my_queue, 2, semaphore)\nmy_worker3 = Worker(my_queue, 3, semaphore)\n\nmy_worker1.start()\nmy_worker2.start()\nmy_worker3.start()\n\nmy_worker1.join()\nmy_worker2.join()\nmy_worker3.join()\n\nprint(\"Done.\")\nSemaphore acquired by Worker 1\nWorker 1: Data 0\nSemaphore acquired by Worker 2\nWorker 2: Data 1\nSemaphore released by Worker 1\nSemaphore acquired by Worker 1\nWorker 1: Data 3\nSemaphore released by Worker 2\nSemaphore acquired by Worker 2\nWorker 2: Data 4\nSemaphore released by Worker 1\nSemaphore released by Worker 2\nSemaphore acquired by Worker 3\nWorker 3: Data 2\nSemaphore released by Worker 3\nDone.\n重複鎖定（RLock）\nRLock 是一個可重複取得使用權的鎖定功能，它跟普通的 Lock 類似，但是它可以允許同一個執行緒重複取得鎖定的使用權。\n若以普通的 Lock 來說，如果同一個執行緒呼叫了兩次 acquire，則在呼叫第二次的時候，就會被擋住：\n# 建立 Lock\nlock = threading.Lock()\n\n# 取得 Lock\nlock.acquire()\n\n# 重複取得 Lock 的時候，就被擋住！\nlock.acquire()\n如果想要讓同一個執行緒可以重複取得鎖定，可以改用有重複鎖定的 RLock：\n# 建立 RLock\nrlock = threading.RLock()\n\n# 取得 rlock\nrlock.acquire()\n\n# 不能讓多個執行緒同時進的工作...\n\n# 重複取得 rlock\nrlock.acquire()\n\n# 不能讓多個執行緒同時進的工作...\n\n# 釋放 rlock\nself.rlock.release()\n\n# 不能讓多個執行緒同時進的工作...\n\n# 再次釋放 rlock\nself.rlock.release()\nRLock 內部有一個計數器，當執行緒在每次呼叫 RLock 的 acquire 的時候，計數器就會遞增 1，紀錄這個鎖定被取得了幾多少次，如果呼叫了 release 時，該計數器就會遞減 1，當計數器遞減至 0 得時候，才會真正釋放鎖定，讓其他的執行緒使用，而在 RLock 的計數器還處於大於 0 的狀態時，其它的執行緒都無法取得這個鎖定的使用權。\n參考資料：Python 官方文件、tutorialspoint、chriskiehl.com、Python 官方文件、莫煩Python、Zhou’s Blog\n",
    "response": "OK"
}
```